---
title: "Tackling The Reproducibility Crisis In Ecology"
subtitle: "ESA Annual Meeting 2024"
author: "Peter Levy, UK Centre for Ecology & Hydrology"
date: "</br> `r Sys.Date()`"
format:
  revealjs:
    theme: [default, ceh.scss]  
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: images/logo/UKCEH-Logo_Short_Positive_RGB.png
---

```{r render, eval = FALSE, include=FALSE}
# use quarto installed with Rstudio; set path first time
# Sys.setenv(QUARTO_PATH="C:/Program Files/RStudio/resources/app/bin/quarto/bin/quarto.exe")
# renv::install("leaflet")
library(quarto)
system.time(quarto_render("./index.qmd"))
```

```{r startup}
library(data.table)
library(ggplot2)
```
## The Reproducibility Crisis
1. What it means
2. The cause - high "false discovery" rates
3. An ecological example: soil carbon change
4. Solutions: a change in perspective in statistical thinking

## The Reproducibility Crisis
::: columns
::: {.column width="60%"}
![\label{fig:Ioannidis2005} Ioannidis, 2005, PLOS Medicine](images/Ioannidis2005.png)
:::
::: {.column width="40%"}


"Reproducibility" of results, not methods.
:::
:::

## The Reproducibility Crisis
::: columns
::: {.column width="60%"}
![\label{fig:Ioannidis2005} https://doi.org/10.1371/journal.pmed.0020124](images/Ioannidis2005.png)
:::

::: {.column width="40%"}
*"The real purpose of scientific method is to make sure Nature hasn't misled you into thinking you know something you don't actually know."*

Robert Pirsig
:::
:::

## Unpublished work as Dark Matter {background="#43464B" background-image="images/milky-way.jpeg"}

```{r darkmatter}
library(magrittr)
library(dplyr)
library(ggplot2)

y <- rnorm(10000, 0, 33)
# hist(y)
cutoff <- quantile(y, probs = 0.95)

df_dens <- density(y, from = -100, to = 100) %$% 
  data.frame(x = x, y = y) %>% 
  mutate(area = x >= cutoff)
names(df_dens) <- c("Effect_size", "Frequency", "Published")
p <- ggplot(data = df_dens, aes(x = Effect_size, ymin = 0, ymax = Frequency, fill = Published)) +
  geom_ribbon() +
  scale_fill_manual(values = c("dark grey", "yellow")) +
  geom_line(aes(y = Frequency)) +
  geom_vline(xintercept = cutoff, colour = "red") +
  annotate(geom = 'text', x = cutoff, y = 0.0125, colour = "red", label = 'Significant at p=5%', hjust = -0.1)
print(p)
```
We can only see 5% of the universe.

<!--- {reproducibility crisis -->
## *"Why most published research findings are false"*

High "false discovery rates", often much higher than 5 %

because of:

- low prior $P(\mathrm{effect})$ - unlikely / rare effects
- low statistical power - low signal:noise
- bias - systematic uncertainty
<!--- } -->

# Understanding false discovery rates {background="#37a635"}

## Disease testing    
![](images/false_discovery_covid.png)

## Generic experiments    
![](images/false_discovery_expt_1.png)
        
## Generic experiments
![](images/false_discovery_expt_2.png)
            
## Effect of prior probability
```{r plotfdr}
alpha <- 0.05
v_power <- c(0.2, 0.4, 0.8)
v_prior <- seq(from = 0, to = 1, by = 0.01)
v_bias  <- seq(from = 0, to = 1, by = 0.05)
dt <- as.data.table(expand.grid(power = v_power, prior = v_prior, u = v_bias))

# expected fdr, from Colquhoun 2014
dt[, ppv := (prior * power)  / (prior * power  + alpha * (1 - prior))]
dt[, fdr := 1 - ppv]

# without bias, from Ioannidis 2005
dt[, R := prior / (1- prior)] # prior odds
# dt[, PPV := power * R / (R - (1 - power) * R + alpha)]
# with bias, u, from Ioannidis 2005
dt[, ppv_u := (power * R + u * (1- power) * R) / 
  (R + alpha - (1 - power) * R + u - u * alpha + u * (1 - power) * R)]
dt[, fdr_u := 1 - ppv_u]

p <- ggplot(dt[power == 0.8], aes(prior, fdr*100, colour = as.factor(power), group = power))
p <- p + geom_line() + ylim(0, 100)
p <- p + xlab("Prior probability") + ylab("False Discovery Rate (%)")
# add legend title
p <- p + scale_color_discrete(name = "Power")
p
```

## Generic experiments: low power  
![](images/false_discovery_expt_3.png)

## Effect of low power
```{r lowpower}
p <- ggplot(dt, aes(prior, fdr*100, colour = as.factor(power), group = power))
p <- p + geom_line() + ylim(0, 100)
p <- p + xlab("Prior probability") + ylab("False Discovery Rate (%)")
# add legend title
p <- p + scale_color_discrete(name = "Power")
p
```

## Generic experiments: bias
![](images/false_discovery_expt_4.png)

## Effect of bias
```{r bias}
p <- ggplot(dt[prior == 0.5], aes(u, fdr_u*100, colour = as.factor(power), group = power))
p <- p + geom_line() + ylim(0, 100) + xlim(0, 1)
p <- p + xlab("Bias") + ylab("False Discovery Rate (%)")
p <- p + scale_color_discrete(name = "Power")
#p <- p + facet_wrap(~ power, ncol = 1)
p
```

# An ecological example: soil carbon change {background="#37a635"}

## "Nature-based solutions" to climate change

::: columns
::: {.column width="40%"}
- "rejuvenative farming"
- biochar
- reduced stocking
- rewilding
:::

::: {.column width="60%"}
![](images/soc_activities.png){.border .border-thick}
:::
:::

## "Nature-based solutions" to climate change

::: columns
::: {.column width="40%"}
BUT:

- change in soil carbon very hard to verify
- huge potential for "greenwashing"
:::

::: {.column width="60%"}
![](images/soc_activities.png){.border .border-thick}
:::
:::

## Measuring soil carbon: field
![](images/soil_coring_1.png)
![](images/soil_coring_2.png)
Take soil cores
![](images/soil_core.png)

## Measuring soil carbon: lab
![](images/measuring_LOI.png)

## Soil carbon: integrate over depth

::: columns
::: {.column width="70%"}
![](images/soil_C_with_depth.png)
:::

::: {.column width="30%"}
$\mathrm{log} C = \alpha + \beta \times \mathrm{depth}$
:::
:::

## Soil carbon: integrate over space

::: columns
::: {.column width="70%"}
![](images/EC_SoilC_maps_eachYear.png)
:::

::: {.column width="30%"}
Extrapolate samples to whole field with spatial model

$\mu_{\mathrm{field}} = f(\theta, C_{\mathrm{samples}})$
:::
:::

## Soil carbon: uncertainties

>- We would typically say we have "measurements of soil carbon".
>- But we actually have measurements of weight loss
>- from a sample of a sample ...
>- from which we predict carbon fraction with a model ...
>- and predict carbon stock to depth with a model ...
>- and extrapolate this in space with a model ...
>- and we (usually) ignore most of the uncertainties!

## Soil carbon: uncertainties

It gets worse.

>- Systematic uncertainties (bias) from different:
    - surveyors
    - sampling protocols
    - areas & depths sampled
    - labs & instruments
    - lab protocols
>- very hard to be consistent over ~20 years.

## Results
Plot of FDR for typical experiments with typical power and bias
Bias is the killer

## The ASA statement
::: columns
::: {.column width="50%"}
![](images/Wasserstein.png)

2016
:::
::: {.column width="50%"}
![](images/Wasserstein2.png)
2019
:::
:::
 Stop using *p* values and "statistical significance".

## 
::: columns
::: {.column width="50%"}
*"All models are wrong, but some are useful."*

George Box, 1976.

![](images/george_box.jpg){width="50%"}
:::
::: {.column width="50%"}

:::
:::

## 
::: columns
::: {.column width="50%"}
*"All models are wrong, but some are useful."*

George Box, 1976.

![](images/george_box.jpg){width="50%"}
:::
::: {.column width="50%"}
*"All [data]{style="color:red"} are wrong, but some are useful."*

Patterson & Gimlin, 1967

![](images/bigfoot.jpg)
:::
:::

## A Copernican Revolution {background-color="white" background-video="images/copernican_revolution.mp4"}
